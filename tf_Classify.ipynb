{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         총장  어깨너비  가슴단면  소매길이  성별    키  몸무게   후기\n",
      "0      67.0  52.0  57.0  58.0   0  159   56  적당함\n",
      "1      67.0  52.0  57.0  58.0   0  163   47    큼\n",
      "2      67.0  52.0  57.0  58.0   0  163   52  적당함\n",
      "3      67.0  52.0  57.0  58.0   0  160   42    큼\n",
      "4      67.0  52.0  57.0  58.0   0  162   55  적당함\n",
      "...     ...   ...   ...   ...  ..  ...  ...  ...\n",
      "18136  74.0  53.0  61.0  67.0   1  178   76  적당함\n",
      "18137  74.0  53.0  61.0  67.0   1  179   78  적당함\n",
      "18138  74.0  53.0  61.0  67.0   1  181   70  적당함\n",
      "18139  74.0  53.0  61.0  67.0   1  186   65  적당함\n",
      "18140  74.0  53.0  61.0  67.0   1  186   65  적당함\n",
      "\n",
      "[16453 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# 추출한 데이터 불러오기\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cats = {\n",
    "    \"반팔\": \"001001\",\n",
    "    \"맨투맨\": \"001005\",\n",
    "    \"후드집업\": \"002022\",\n",
    "    \"숏패딩\": \"002012\",\n",
    "    \"데님팬츠\": \"003002\",\n",
    "    \"코튼팬츠\": \"003007\",\n",
    "}\n",
    "selected_cat = \"맨투맨\"\n",
    "\n",
    "# Encode categorical variables (gender) using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "dir = \"datasets/\"\n",
    "file_name = dir + selected_cat + \"_data.csv\"\n",
    "data = pd.read_csv(file_name)\n",
    "data = data[[\"총장\", \"어깨너비\", \"가슴단면\", \"소매길이\", \"성별\", \"키\", \"몸무게\", \"후기\"]].dropna(axis=0)\n",
    "#data = data[[\"총장\", \"허리단면\", \"엉덩이단면\", \"허벅지단면\", \"밑위\", \"밑단단면\", \"성별\", \"키\", \"몸무게\", \"후기\"]].dropna(axis=0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후기를 제외한 열은 입력 데이터로 사용\n",
    "# 후기는 타깃 데이터\n",
    "#총장,허리단면,엉덩이단면,허벅지단면,밑위,밑단단면,성별,키,몸무게,후기\n",
    "\n",
    "data_input = data[[\"총장\", \"어깨너비\", \"가슴단면\", \"소매길이\", \"성별\", \"키\", \"몸무게\"]].to_numpy()\n",
    "#data_input = data[[\"총장\", \"허리단면\", \"엉덩이단면\", \"허벅지단면\", \"밑위\", \"밑단단면\", \"성별\", \"키\", \"몸무게\"]].to_numpy()\n",
    "data_target = data[\"후기\"].to_numpy()\n",
    "\n",
    "rv2num = {\"큼\": 2, \"적당함\": 1, \"작음\": 0}\n",
    "for i in range(len(data_target)):\n",
    "    data_target[i] = rv2num[data_target[i]]\n",
    "data_target = data_target.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의 train_test_split() 함수를 이용해 이 데이터를 훈련 세트와 테스트 세트로 나눔\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    data_input, data_target, random_state=42\n",
    ")\n",
    "\n",
    "data_input = scaler.fit_transform(data_input)\n",
    "test_input = scaler.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "309/309 [==============================] - 2s 7ms/step - loss: 5.4007 - accuracy: 0.7050 - val_loss: 1.6474 - val_accuracy: 0.7958\n",
      "Epoch 2/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 1.3897 - accuracy: 0.7149 - val_loss: 0.7549 - val_accuracy: 0.8079\n",
      "Epoch 3/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 1.1629 - accuracy: 0.7282 - val_loss: 0.6917 - val_accuracy: 0.8063\n",
      "Epoch 4/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 1.0604 - accuracy: 0.7289 - val_loss: 0.9809 - val_accuracy: 0.7978\n",
      "Epoch 5/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.9281 - accuracy: 0.7369 - val_loss: 0.8654 - val_accuracy: 0.7962\n",
      "Epoch 6/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.9430 - accuracy: 0.7360 - val_loss: 0.7735 - val_accuracy: 0.7581\n",
      "Epoch 7/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.8537 - accuracy: 0.7447 - val_loss: 0.7075 - val_accuracy: 0.7986\n",
      "Epoch 8/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.8097 - accuracy: 0.7434 - val_loss: 1.0867 - val_accuracy: 0.4275\n",
      "Epoch 9/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.8794 - accuracy: 0.7320 - val_loss: 0.5918 - val_accuracy: 0.8031\n",
      "Epoch 10/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7586 - accuracy: 0.7536 - val_loss: 0.5678 - val_accuracy: 0.8083\n",
      "Epoch 11/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7796 - accuracy: 0.7467 - val_loss: 0.7643 - val_accuracy: 0.7958\n",
      "Epoch 12/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7836 - accuracy: 0.7496 - val_loss: 0.6050 - val_accuracy: 0.8011\n",
      "Epoch 13/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7833 - accuracy: 0.7471 - val_loss: 0.5108 - val_accuracy: 0.8124\n",
      "Epoch 14/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7667 - accuracy: 0.7480 - val_loss: 0.8370 - val_accuracy: 0.7954\n",
      "Epoch 15/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.8046 - accuracy: 0.7469 - val_loss: 0.5077 - val_accuracy: 0.8124\n",
      "Epoch 16/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7769 - accuracy: 0.7460 - val_loss: 0.5904 - val_accuracy: 0.7994\n",
      "Epoch 17/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7680 - accuracy: 0.7475 - val_loss: 0.5282 - val_accuracy: 0.8043\n",
      "Epoch 18/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7850 - accuracy: 0.7458 - val_loss: 0.5874 - val_accuracy: 0.8092\n",
      "Epoch 19/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7114 - accuracy: 0.7602 - val_loss: 0.6411 - val_accuracy: 0.7889\n",
      "Epoch 20/20\n",
      "309/309 [==============================] - 2s 6ms/step - loss: 0.7221 - accuracy: 0.7503 - val_loss: 0.5317 - val_accuracy: 0.8043\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.9718 - accuracy: 0.7389\n",
      "Test Accuracy: 0.7389401793479919\n",
      "129/129 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_dim=data_input.shape[1]),\n",
    "    tf.keras.layers.Dropout(0.5),  # Corrected: Use a comma instead of a semicolon\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: small, moderate, large\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Corrected: Use sparse_categorical_crossentropy\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_input, train_target, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_input, test_target)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "# 표를 불러오기 위한 라이브러리\n",
    "from html_table_parser import parser_functions as parser\n",
    "import collections\n",
    "\n",
    "collections.Callable = collections.abc.Callable\n",
    "# 403 에러 방지\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# https://www.musinsa.com/app/goods/3574305\n",
    "# 0, 180, 80\n",
    "url = input(\"url 주소를 입력하세요\")\n",
    "# Collect additional user information (gender, height, weight)\n",
    "user_gender = input(\"Enter your gender (if 'Male' 0, if 'Female' 1): \")\n",
    "user_height = float(input(\"Enter your height in centimeters: \"))\n",
    "user_weight = float(input(\"Enter your weight in kilograms: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = {\"성별\": [user_gender], \"키\":[user_height], \"몸무게\":[user_weight]}\n",
    "user_info = pd.DataFrame(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   총장 어깨너비 가슴단면 소매길이 성별      키   몸무게\n",
      "0  61   49   53   58  0  180.0  80.0\n",
      "1  68   52   58   60  0  180.0  80.0\n",
      "2  71   55   60   62  0  180.0  80.0\n",
      "3  74   57   65   64  0  180.0  80.0\n",
      "4  79   65   70   65  0  180.0  80.0\n",
      "5  82   68   75   66  0  180.0  80.0\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(url, headers=headers)\n",
    "soup = bs(page.text, \"lxml\")\n",
    "table = soup.find_all(attrs={\"class\": \"table_th_grey\"})\n",
    "\n",
    "p = parser.make2d(table[0])\n",
    "p[0][0] = \"사이즈\"\n",
    "size_df = pd.DataFrame(p[3:], columns=p[0])\n",
    "\n",
    "num_rows = len(size_df)\n",
    "user_info = pd.concat([user_info] * num_rows, ignore_index=True)\n",
    "user_df = pd.concat([size_df, user_info], axis = 1)\n",
    "user_df=user_df[[\"총장\", \"어깨너비\", \"가슴단면\", \"소매길이\", \"성별\", \"키\", \"몸무게\"]].dropna(axis=0)\n",
    "\n",
    "print(user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   총장 어깨너비 가슴단면 소매길이 성별      키   몸무게\n",
      "0  61   49   53   58  0  180.0  80.0\n",
      "1  68   52   58   60  0  180.0  80.0\n",
      "2  71   55   60   62  0  180.0  80.0\n",
      "3  74   57   65   64  0  180.0  80.0\n",
      "4  79   65   70   65  0  180.0  80.0\n",
      "5  82   68   75   66  0  180.0  80.0\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "[[0.39991853 0.37720445 0.22287704]\n",
      " [0.33984292 0.38156816 0.27858898]\n",
      " [0.31036392 0.37966463 0.3099714 ]\n",
      " [0.26809487 0.37417218 0.35773298]\n",
      " [0.21531238 0.3606924  0.42399517]\n",
      " [0.18046397 0.345928   0.47360805]]\n",
      "M small 0.39991853\n",
      "L good 0.38156816\n",
      "XL good 0.37966463\n",
      "2XL good 0.37417218\n",
      "3XL large 0.42399517\n",
      "4XL large 0.47360805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the user's input\n",
    "# Ensure the column order and preprocessing steps match your training data preprocessing\n",
    "user_df=user_df[[\"총장\", \"어깨너비\", \"가슴단면\", \"소매길이\", \"성별\", \"키\", \"몸무게\"]].dropna(axis=0)\n",
    "print(user_df)\n",
    "user_df[[\"총장\", \"어깨너비\", \"가슴단면\", \"소매길이\", \"성별\", \"키\", \"몸무게\"]] = scaler.transform(user_df[[\"총장\", \"어깨너비\", \"가슴단면\", \"소매길이\", \"성별\", \"키\", \"몸무게\"]])\n",
    "\n",
    "# Make predictions for each row\n",
    "user_predictions = model.predict(user_df.to_numpy())\n",
    "\n",
    "print(user_predictions)\n",
    "\n",
    "# Get the predicted class for each row\n",
    "predicted_classes = np.argmax(user_predictions, axis=1)\n",
    "predicted_probablities = np.max(user_predictions, axis=1)\n",
    "\n",
    "# Map the predicted classes back to size satisfaction categories\n",
    "num2rv = {2: \"large\", 1: \"good\", 0: \"small\"}\n",
    "predicted_size_satisfactions = [num2rv[predicted_class] for predicted_class in predicted_classes]\n",
    "\n",
    "# Add the predicted size satisfaction as a new column to the user_input DataFrame\n",
    "user_df[\"Predicted Size Satisfaction\"] = predicted_size_satisfactions\n",
    "user_df[\"Predicted Probabilities\"] = predicted_probablities\n",
    "\n",
    "\n",
    "# Display the results\n",
    "for i in range(num_rows):\n",
    "    print(size_df['사이즈'][i], user_df['Predicted Size Satisfaction'][i], user_df['Predicted Probabilities'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
